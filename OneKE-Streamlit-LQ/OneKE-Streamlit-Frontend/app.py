import streamlit as st
import json
import os
import sys
import tempfile
import random
import re
from pathlib import Path
from typing import Dict, Any, Optional
import streamlit.components.v1 as components
from pyvis.network import Network
import networkx as nx
from components.sidebar import render_sidebar
from components.results import render_results
from config.settings import (
    APP_CONFIG, MODEL_CONFIG, TASK_CONFIG, NEO4J_CONFIG, 
    PROXY_CONFIG, FILE_CONFIG, UI_CONFIG, ERROR_MESSAGES,
    ONEKE_CONFIG, APP_INFO, SESSION_DEFAULTS
)
from tools.examples import get_examples, get_example_by_index

try:
    from neo4j import GraphDatabase
    NEO4J_AVAILABLE = True
except ImportError:
    NEO4J_AVAILABLE = False

# ä»£ç†è®¾ç½®å‡½æ•° - æ”¯æŒç”¨æˆ·é…ç½®
def set_proxy_config(enable_proxy=PROXY_CONFIG["default_enabled"], 
                    proxy_host=PROXY_CONFIG["default_host"], 
                    proxy_port=PROXY_CONFIG["default_port"]):
    """è®¾ç½®ä»£ç†é…ç½®
    
    Args:
        enable_proxy (bool): æ˜¯å¦å¯ç”¨ä»£ç†
        proxy_host (str): ä»£ç†æœåŠ¡å™¨åœ°å€
        proxy_port (str): ä»£ç†ç«¯å£
    """
    if enable_proxy:
        proxy_url = f"http://{proxy_host}:{proxy_port}"
        for var in PROXY_CONFIG["environment_variables"]:
            if var == 'USE_PROXY':
                os.environ[var] = 'true'
            else:
                os.environ[var] = proxy_url
        print(f"ğŸ”§ ä»£ç†å·²å¯ç”¨: {proxy_url}")
    else:
        # æ¸…é™¤ä»£ç†è®¾ç½®
        for key in PROXY_CONFIG["environment_variables"]:
            os.environ.pop(key, None)
        print("âŒ ä»£ç†å·²ç¦ç”¨")

# åˆå§‹åŒ–æ—¶ä¸è®¾ç½®ä»£ç†ï¼Œç­‰å¾…ç”¨æˆ·é…ç½®
# print("âš™ï¸ ä»£ç†é…ç½®å°†ç”±ç”¨æˆ·åœ¨ç•Œé¢ä¸­è®¾ç½®")

# æ·»åŠ OneKEæºç è·¯å¾„
oneke_path = ONEKE_CONFIG["source_path"]
if oneke_path.exists():
    sys.path.insert(0, str(oneke_path))
    
    try:
        from models import *
        from pipeline import Pipeline
        from utils import *
        ONEKE_AVAILABLE = True
        
        # å°è¯•å¯¼å…¥constructæ¨¡å—
        try:
            from construct.convert import generate_cypher_statements, execute_cypher_statements
            CONSTRUCT_AVAILABLE = True
        except ImportError:
            CONSTRUCT_AVAILABLE = False
    except ImportError as e:
        st.error(f"Failed to import OneKE modules: {e}")
        ONEKE_AVAILABLE = False
        CONSTRUCT_AVAILABLE = False
else:
    ONEKE_AVAILABLE = False
    CONSTRUCT_AVAILABLE = False
    st.warning(ERROR_MESSAGES["oneke_not_available"])

# OneKEProcessorä¸å†éœ€è¦ï¼Œç›´æ¥ä½¿ç”¨Pipeline


# ç»“æœå±•ç¤ºç›¸å…³å‡½æ•°å·²ç§»åŠ¨åˆ° components/results.py

# å¯¼å…¥ç¤ºä¾‹æ•°æ®

examples = get_examples()

def get_model_category(model_name_or_path):
    """è·å–æ¨¡å‹ç±»åˆ«ï¼Œå¤åˆ¶è‡ªwebui.py"""
    if model_name_or_path in MODEL_CONFIG["supported_models"]["gpt"]:
        return ChatGPT
    elif model_name_or_path in MODEL_CONFIG["supported_models"]["deepseek"]:
        return DeepSeek
    elif re.search(r'(?i)' + MODEL_CONFIG["supported_models"]["llama"], model_name_or_path):
        return LLaMA
    elif re.search(r'(?i)' + MODEL_CONFIG["supported_models"]["qwen"], model_name_or_path):
        return Qwen
    elif re.search(r'(?i)' + MODEL_CONFIG["supported_models"]["minicpm"], model_name_or_path):
        return MiniCPM
    elif re.search(r'(?i)' + MODEL_CONFIG["supported_models"]["chatglm"], model_name_or_path):
        return ChatGLM
    else:
        return BaseEngine

def start_with_example():
    """éšæœºé€‰æ‹©ä¸€ä¸ªç¤ºä¾‹ï¼Œå¤åˆ¶è‡ªwebui.py"""
    example_index = random.randint(-3, len(examples) - 1)
    example_index = max(example_index, 0)
    example = get_example_by_index(example_index)
    
    if example_index == 0:
        from config.settings import EXAMPLES_CONFIG
        with open(EXAMPLES_CONFIG["chinese_news_file"], "r", encoding="utf-8") as file:
            lines = file.readlines()
            random_line = random.choice(lines).strip()
            try:
                json_data = json.loads(random_line)
                title = json_data.get("title", "No title found")
            except json.JSONDecodeError:
                title = "Error decoding JSON"
            example["text"] = title
    
    return example



# é¡µé¢é…ç½®
st.set_page_config(
    page_title=APP_CONFIG["page_title"],
    page_icon=APP_CONFIG["page_icon"],
    layout=APP_CONFIG["layout"],
    initial_sidebar_state=APP_CONFIG["initial_sidebar_state"]
)

# åˆå§‹åŒ–session state
for key, default_value in SESSION_DEFAULTS.items():
    if key not in st.session_state:
        st.session_state[key] = default_value

def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    
    # é¡µé¢æ ‡é¢˜å’Œæè¿° - åŸºäºOneKEé¡¹ç›®çš„Streamlitå‰ç«¯
    # åŸOneKEé¡¹ç›®ä¿¡æ¯ï¼ˆå·²æ³¨é‡Šï¼‰:
    # OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System
    # ğŸŒHome: http://oneke.openkg.cn/
    # ğŸ“¹Video: http://oneke.openkg.cn/demo.mp4
    
    st.markdown(f"""
    <div style="text-align:center;">
        <h1>{APP_INFO["title"]}</h1>
        <p style="font-size: 18px; color: #666; margin-bottom: 10px;">
            {APP_INFO["description"]}
        </p>
        <p>
        ğŸ“<a href="{APP_INFO["links"]["paper"]}" target="_blank">OneKE Paper</a> |
        ğŸ’»<a href="{APP_INFO["links"]["code"]}" target="_blank">OneKE Code</a>
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # è·å–å½“å‰ç¤ºä¾‹æ•°æ®ï¼ˆå¿…é¡»åœ¨ä¾§è¾¹æ é…ç½®ä¹‹å‰å®šä¹‰ï¼‰
    current_example = st.session_state.get("current_example") or {}
    
    # éšæœºç¤ºä¾‹æŒ‰é’®
    col_example1, col_example2, col_example3 = st.columns([1, 2, 1])
    with col_example2:
        if st.button("ğŸ² Quick Start with an Example ğŸ²", type="primary", use_container_width=True):
            example = start_with_example()
            st.session_state.current_example = example
            st.rerun()
    
    # ä¾§è¾¹æ é…ç½®
    sidebar_config = render_sidebar()
    
    # ä»ä¾§è¾¹æ é…ç½®ä¸­æå–å˜é‡
    model_name = sidebar_config["model_name"]
    api_key = sidebar_config["api_key"]
    base_url = sidebar_config["base_url"]
    task_type = sidebar_config["task_type"]
    mode = sidebar_config["mode"]
    agent_config = sidebar_config["agent_config"]
    neo4j_config = sidebar_config["neo4j_config"]
    
    # ä¸ºäº†å…¼å®¹ç°æœ‰ä»£ç ï¼Œè®¾ç½®Neo4jç›¸å…³å˜é‡
    if task_type == "Triple":
        neo4j_url = neo4j_config.get("url", "")
        neo4j_username = neo4j_config.get("username", "")
        neo4j_password = neo4j_config.get("password", "")
        enable_kg_construction = neo4j_config.get("enable_kg_construction", False)
    else:
        neo4j_url = ""
        neo4j_username = ""
        neo4j_password = ""
        enable_kg_construction = False
        

    
    # ä¸»å†…å®¹åŒºåŸŸ
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.header("ğŸ“ Input Configuration")
        
        # è¾“å…¥æ–¹å¼é€‰æ‹©
        default_use_file = current_example.get("use_file", False)
        use_file = st.checkbox(
            "ğŸ“‚ Use File",
            value=default_use_file,
            help="Choose between file upload or text input"
        )
        
        # æ–‡ä»¶ä¸Šä¼ æˆ–æ–‡æœ¬è¾“å…¥
        input_text = ""
        uploaded_file = None
        example_file_loaded = False
        
        if use_file:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç¤ºä¾‹æ–‡ä»¶éœ€è¦åŠ è½½
            example_file_path = current_example.get("file_path")
            if example_file_path and os.path.exists(example_file_path):
                # æ˜¾ç¤ºç¤ºä¾‹æ–‡ä»¶ä¿¡æ¯
                st.info(f"ğŸ“ Example file loaded: {os.path.basename(example_file_path)}")
                st.info("ğŸ“„ File will be processed by OneKE backend")
                input_text = f"[File: {os.path.basename(example_file_path)}]"
                
                # æ ‡è®°ç¤ºä¾‹æ–‡ä»¶å·²åŠ è½½
                example_file_loaded = True
            
            # å¦‚æœæ²¡æœ‰åŠ è½½ç¤ºä¾‹æ–‡ä»¶ï¼Œæ˜¾ç¤ºæ–‡ä»¶ä¸Šä¼ å™¨
            if not example_file_loaded:
                uploaded_file = st.file_uploader(
                "ğŸ“– Upload a File",
                type=FILE_CONFIG["supported_extensions"],
                help="Upload a text file, PDF, Word document, HTML file, or JSON file"
            )
            
            if uploaded_file is not None:
                # æ‰€æœ‰æ–‡ä»¶éƒ½äº¤ç»™OneKEåç«¯å¤„ç†
                st.success(f"âœ… Uploaded {uploaded_file.name} - will be processed by OneKE backend")
                input_text = f"[File uploaded: {uploaded_file.name}]"
            else:
                input_text = ""
        else:
            # æ–‡æœ¬è¾“å…¥
            default_text = current_example.get("text", "")
            input_text = st.text_area(
                "ğŸ“– Text",
                value=default_text,
                height=UI_CONFIG["text_area_height"]["text_input"],
                placeholder=UI_CONFIG["placeholders"]["text_input"],
                help=UI_CONFIG["help_texts"]["text_input"]
            )
        
        if task_type == "Base":
            # Baseä»»åŠ¡æ˜¾ç¤ºinstructionå’Œoutput_schemaè¾“å…¥
            default_instruction = current_example.get("instruction", "")
            instruction = st.text_area(
                "ğŸ•¹ï¸ Instruction",
                value=default_instruction,
                height=UI_CONFIG["text_area_height"]["instruction"],
                placeholder=UI_CONFIG["placeholders"]["instruction"],
                help=UI_CONFIG["help_texts"]["instruction"]
            )
            
            default_output_schema = current_example.get("output_schema", "")
            output_schema = st.text_area(
                "ğŸ“‹ Output Schema (Optional)",
                value=default_output_schema,
                height=UI_CONFIG["text_area_height"]["output_schema"],
                placeholder=UI_CONFIG["placeholders"]["output_schema"],
                help=UI_CONFIG["help_texts"]["output_schema"]
            )
            
            # Baseä»»åŠ¡constraintå¼ºåˆ¶ä¸ºç©º
            constraint = ""
        else:
            # å…¶ä»–ä»»åŠ¡åªæ˜¾ç¤ºconstraintè¾“å…¥ï¼Œinstructionä½¿ç”¨é¢„è®¾å€¼
            default_constraint = current_example.get("constraint", "")
            
            # ä¸ºä¸åŒä»»åŠ¡ç±»å‹æä¾›ä¸åŒçš„çº¦æŸæ ¼å¼æç¤º
            constraint_placeholder = TASK_CONFIG["constraint_placeholders"].get(task_type, 'Enter constraints')
            constraint_help = TASK_CONFIG["constraint_help_texts"].get(task_type, 'Define constraints for the task')
            
            constraint = st.text_area(
                "ğŸ•¹ï¸ Constraint",
                value=default_constraint,
                height=UI_CONFIG["text_area_height"]["constraint"],
                placeholder=constraint_placeholder,
                help=constraint_help
            )
            
            # å…¶ä»–ä»»åŠ¡instructionå’Œoutput_schemaä½¿ç”¨é¢„è®¾å€¼
            instruction = ""
            output_schema = ""
        
        # æ›´æ–°æ¡ˆä¾‹é€‰é¡¹
        default_update_case = current_example.get("update_case", False)
        update_case = st.checkbox(
            "ğŸ’° Update Case",
            value=default_update_case,
            help=UI_CONFIG["help_texts"]["update_case"]
        )
        
        # çœŸå€¼è¾“å…¥ï¼ˆä»…åœ¨æ›´æ–°æ¡ˆä¾‹æ—¶æ˜¾ç¤ºï¼‰
        truth = ""
        if update_case:
            default_truth = current_example.get("truth", "")
            truth = st.text_area(
                "ğŸª™ Truth",
                value=default_truth,
                height=UI_CONFIG["text_area_height"]["truth"],
                placeholder=UI_CONFIG["placeholders"]["truth"],
                help=UI_CONFIG["help_texts"]["truth"]
            )
        
        # æ‰§è¡ŒæŠ½å–æŒ‰é’®
        if st.button("ğŸš€ Submit", type="primary"):
            with st.spinner(f"Performing {task_type} extraction in {mode} mode..."):
                try:
                    # æŒ‰ç…§webui.pyçš„submitå‡½æ•°é€»è¾‘é‡æ–°åˆ›å»ºPipeline
                    ModelClass = get_model_category(model_name)
                    if base_url == "Default" or base_url == "":
                        if api_key == "":
                            pipeline = Pipeline(ModelClass(model_name_or_path=model_name))
                        else:
                            pipeline = Pipeline(ModelClass(model_name_or_path=model_name, api_key=api_key))
                    else:
                        if api_key == "":
                            pipeline = Pipeline(ModelClass(model_name_or_path=model_name, base_url=base_url))
                        else:
                            pipeline = Pipeline(ModelClass(model_name_or_path=model_name, api_key=api_key, base_url=base_url))
                    
                    # æ ¹æ®ä»»åŠ¡ç±»å‹å¤„ç†å‚æ•°ï¼ˆéµå¾ªåŸå§‹OneKEè®¾è®¡ï¼‰
                    if task_type == "Base":
                        # Baseä»»åŠ¡ï¼šä½¿ç”¨instructionï¼Œconstraintå¼ºåˆ¶ä¸ºç©º
                        instruction = instruction
                        constraint = ""
                    else:
                        # å…¶ä»–ä»»åŠ¡ï¼šä½¿ç”¨constraintï¼Œinstructionå¼ºåˆ¶ä¸ºç©ºï¼ˆä½¿ç”¨configä¸­çš„é¢„è®¾å€¼ï¼‰
                        instruction = ""
                        constraint = constraint
                    
                    schema_agent = agent_config.get("schema_agent", "Not Required") if mode == "customized" and agent_config else "Not Required"
                    extraction_Agent = agent_config.get("extraction_Agent", "Not Required") if mode == "customized" and agent_config else "Not Required"
                    reflection_agent = agent_config.get("reflection_agent", "Not Required") if mode == "customized" and agent_config else "Not Required"
                    
                    # æŒ‰ç…§webui.pyçš„é€»è¾‘æ„å»ºagent3å­—å…¸
                    agent3 = {}
                    if mode == "customized":
                        if schema_agent not in ["", "Not Required"]:
                            agent3["schema_agent"] = schema_agent
                        if extraction_Agent not in ["", "Not Required"]:
                            agent3["extraction_agent"] = extraction_Agent
                        if reflection_agent not in ["", "Not Required"]:
                            agent3["reflection_agent"] = reflection_agent
                    
                    # æŒ‰ç…§webui.pyçš„é€»è¾‘å¤„ç†textå’Œfile_pathå‚æ•°
                    if use_file:
                        text_param = ""
                        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç¤ºä¾‹æ–‡ä»¶
                        example_file_path = current_example.get("file_path")
                        if example_file_path and os.path.exists(example_file_path):
                            # ä½¿ç”¨ç¤ºä¾‹æ–‡ä»¶è·¯å¾„
                            file_path_param = example_file_path
                        elif uploaded_file is not None:
                            # å¯¹äºStreamlitï¼Œæˆ‘ä»¬éœ€è¦å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
                            # æ ¹æ®æ–‡ä»¶ç±»å‹ç¡®å®šåç¼€å
                            file_extension = os.path.splitext(uploaded_file.name)[1]
                            if not file_extension:
                                file_extension = '.txt'
                            
                            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                            with tempfile.NamedTemporaryFile(mode='wb', delete=False, suffix=file_extension) as tmp_file:
                                # é‡ç½®æ–‡ä»¶æŒ‡é’ˆåˆ°å¼€å§‹ä½ç½®
                                uploaded_file.seek(0)
                                tmp_file.write(uploaded_file.read())
                                file_path_param = tmp_file.name
                        else:
                            file_path_param = None
                    else:
                        text_param = input_text
                        file_path_param = None
                    
                    if not update_case:
                        truth = ""
                    
                    # ä½¿ç”¨Pipelineçš„get_extract_resultæ–¹æ³•ï¼Œä¸webui.pyä¿æŒä¸€è‡´
                    _, _, ger_frontend_schema, ger_frontend_res = pipeline.get_extract_result(
                        task=task_type,
                        text=text_param,
                        use_file=use_file,
                        file_path=file_path_param,
                        instruction=instruction,
                        constraint=constraint,
                        mode=mode,
                        three_agents=agent3,
                        isgui=True,
                        update_case=update_case,
                        truth=truth,
                        output_schema=output_schema,
                        show_trajectory=False,
                    )
                    
                    # æŒ‰ç…§webui.pyçš„é€»è¾‘å¤„ç†ç»“æœ
                    ger_frontend_schema = str(ger_frontend_schema)
                    ger_frontend_res = json.dumps(ger_frontend_res, ensure_ascii=False, indent=4) if isinstance(ger_frontend_res, dict) else str(ger_frontend_res)
                    
                    result = {
                        "success": True,
                        "schema": ger_frontend_schema,
                        "result": ger_frontend_res
                    }
                    st.session_state.extraction_results = result
                    st.success(f"Extraction completed successfully in {mode} mode!")
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆä½†ä¸åˆ é™¤ç¤ºä¾‹æ–‡ä»¶ï¼‰
                    if use_file and file_path_param and os.path.exists(file_path_param):
                        # åªåˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œä¸åˆ é™¤ç¤ºä¾‹æ–‡ä»¶
                        example_file_path = current_example.get("file_path")
                        if file_path_param != example_file_path:
                            try:
                                os.unlink(file_path_param)
                            except:
                                pass
                
                except Exception as e:
                    # å‚è€ƒwebui.pyçš„é”™è¯¯å¤„ç†æ–¹å¼
                    error_message = f"âš ï¸ Error:\n {str(e)}"
                    result = {
                        "success": False,
                        "error": error_message
                    }
                    st.session_state.extraction_results = result
                    st.error(f"Extraction failed: {str(e)}")
                    
                    # æä¾›è¿æ¥é”™è¯¯çš„å…·ä½“å»ºè®®
                    if "Connection error" in str(e) or "connection" in str(e).lower():
                        st.warning("ğŸ’¡ Connection Error Solutions:")
                        for i, solution in enumerate(ERROR_MESSAGES["connection_error_solutions"], 1):
                            st.write(f"{i}. {solution}")
                    
                    # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
                    with st.expander("Detailed Error Information"):
                        st.code(str(e))
        
        
        # æ¸…é™¤æŒ‰é’® - ä¸webui.pyçš„clear_allè¡Œä¸ºä¸€è‡´
        if st.button("ğŸ§¹ Clear All"):
            # é‡ç½®extraction_resultså’Œcurrent_example
            st.session_state.extraction_results = None
            st.session_state.current_example = {}
            st.rerun()
    
    with col2:
        # ä½¿ç”¨æ–°çš„ç»“æœå±•ç¤ºç»„ä»¶
        st.header("ğŸ“Š Results")
        
        if st.session_state.extraction_results:
            result = st.session_state.extraction_results
            render_results(result, task_type)
        else:
            st.info("ğŸ‘† Configure your model and input text to start extraction.")

# create_knowledge_graph_visualization å‡½æ•°å·²ç§»åŠ¨åˆ° components/results.py

if __name__ == "__main__":
    main()
